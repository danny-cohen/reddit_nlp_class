{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638a8206-2102-4037-b9d3-6b2820f4310c",
   "metadata": {},
   "source": [
    "# 01 - Data Collection with PRAW/Reddit API\n",
    "\n",
    "## r/AskAstronomy vs r/AskAstrologers:\n",
    "\n",
    "__Problem statement__:\n",
    "\n",
    "Basic stats:\n",
    "\n",
    "- [r/AskAstronomy](https://www.reddit.com/r/askastronomy/): 54,000 users (top 2%). \n",
    "- [r/AskAstrologers](https://www.reddit.com/r/askastrologers/): 147,000 users (top 1%)\n",
    "\n",
    "\n",
    "\n",
    "Outline\n",
    "\n",
    "1. Define functions to perform webscraping on subreddit pages and combine into a dataframe.\n",
    "\n",
    "2. Collect data from past ~24 hours from each subreddit and merge into a single `DataFrame`.\n",
    "\n",
    "3. Save raw dataframe as csv file.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7bf1914-961b-44ff-8ca6-223fbb883fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745863d",
   "metadata": {},
   "source": [
    "Instantiate `praw.Reddit()` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0463c0b-ea32-44dd-a838-539a0299590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42585c0d-7431-4305-ab7e-2ae6be9933b5",
   "metadata": {},
   "source": [
    "## 1. Functions for scraping subreddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7356c5-b615-414a-8914-c7e5cf3c642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve posts from a subreddit or list of subreddits\n",
    "def get_posts(subreddit, limit=5000, kind='new', last_post=None):\n",
    "    \n",
    "    # retrieve submissions from subreddit new\n",
    "    if kind=='new':\n",
    "        if last_post is not None:\n",
    "\n",
    "            posts = reddit.subreddit(subreddit).new(limit=limit,params={'after':last_post})\n",
    "        else:\n",
    "\n",
    "            posts = reddit.subreddit(subreddit).new(limit=limit)\n",
    "    # loop through posts and create dictoinary\n",
    "    posts_list=[]\n",
    "    for post in posts:\n",
    "    \n",
    "        posts_list.append(\n",
    "            {\n",
    "                'title':post.title,\n",
    "                'selftext':post.selftext,\n",
    "                'subreddit':post.subreddit,\n",
    "                'created_utc':post.created_utc,\n",
    "                'name':post.name\n",
    "            }\n",
    "\n",
    "        )\n",
    "    # return a dataframe with posts\n",
    "    return pd.DataFrame(posts_list)\n",
    "\n",
    "\n",
    "import datetime\n",
    "# format time column as pandas Datetimeindex and sort chronologically\n",
    "def format_time_col(df):\n",
    "    \n",
    "    utc_created = [datetime.datetime.utcfromtimestamp(int(ts)) for ts in df['created_utc']]\n",
    "    df['created_utc']=pd.DatetimeIndex(utc_created)\n",
    "    df.sort_values(by='created_utc',ascending=False,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# create merged dataframe of two subreddits to save\n",
    "def get_subreddit_data(subreddit_list, limit=5000, last_post=None):\n",
    "    # retieve post dataframe\n",
    "    df = get_posts(\"+\".join([f\"{subreddit}\" for subreddit in subreddit_list]) , limit=limit, last_post=last_post)\n",
    "    \n",
    "    # make subreddit column lowercase\n",
    "    df['subreddit']=df['subreddit'].map(lambda x: str(x).lower())\n",
    "\n",
    "    # format time column\n",
    "    df=format_time_col(df)\n",
    "    \n",
    "    # return dataframe\n",
    "    return df[['name','created_utc','title','selftext','subreddit']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76596d65-dca9-4f56-8bcd-cdb2b72fde72",
   "metadata": {},
   "source": [
    "## 2. Get the r/askastrologers and r/askastronomy dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d3d0b9-7095-496f-9198-c1f53cb9ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_list = ['askastrologers','askastronomy']\n",
    "\n",
    "df_merged = get_subreddit_data(subreddit_list,limit=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79011ee",
   "metadata": {},
   "source": [
    "### Check shape and some example posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788653a8-0267-43fd-8e2d-4436b0534b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1985 entries, 0 to 1984\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   name         1985 non-null   object        \n",
      " 1   created_utc  1985 non-null   datetime64[ns]\n",
      " 2   title        1985 non-null   object        \n",
      " 3   selftext     1985 non-null   object        \n",
      " 4   subreddit    1985 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 93.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89dec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "askastrologers    997\n",
       "askastronomy      988\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0eb4d",
   "metadata": {},
   "source": [
    "__Subreddit post distribution looks pretty even.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9bf351-440f-42bd-a645-1aa7dcaba48f",
   "metadata": {},
   "source": [
    "## 3. Save merged data as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da8418ba-4cff-4c0b-a9c9-5b786cbe95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(f\"../data/data_raw_{'_'.join(subreddit_list)}_{df_merged['created_utc'].iloc[0].strftime('%Y-%m-%d_%H-%M-%S')}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c821eec1-0961-49f8-b87e-0c8d423a73d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_raw_askastrologers_askastronomy_2024-01-27_20-06-07.csv', 'data_raw_askastrologers_askastronomy_2024-01-27_20-55-01.csv', 'data_raw_askastrologers_askastronomy_2024-01-29_14-49-04.csv', 'data_raw_askastrologers_askastronomy_2024-01-29_22-51-36.csv']\n"
     ]
    }
   ],
   "source": [
    "# import os,sys\n",
    "\n",
    "# flist = [str(f) for f in list(os.listdir('../data')) if 'raw_askastrologers' in f]\n",
    "# print(flist)\n",
    "# df_list = [pd.read_csv(f'../data/{f}',index_col='name',\n",
    "#                        parse_dates=['created_utc']) for f in flist]\n",
    "\n",
    "# flist = [flist[i] for i in range(len(df_list)) if 'post' in df_list[i].columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dd960c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list = [pd.read_csv(f'../data/{f}',index_col='name',\n",
    "#                        parse_dates=['created_utc']) for f in flist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcab6bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'title', 'selftext', 'subreddit', 'created_utc', 'post'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_list[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b86e02e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [df.drop(columns=['post'],inplace=True) for df in df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4088553b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [df_list[i].to_csv(flist[i]) for i in range(len(flist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66449d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
